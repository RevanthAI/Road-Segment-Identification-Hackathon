{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# import tensorflow-io as tfio\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "import gctf\n",
    "import os\n",
    "import random \n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from tensorflow.keras.applications import EfficientNetB0,EfficientNetB3,EfficientNetB5\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten,GlobalAveragePooling2D,BatchNormalization, Activation\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from tensorflow.keras.losses import BinaryCrossentropy \n",
    "from tensorflow.keras.metrics import AUC"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class config:\n",
    "    seed=42\n",
    "    batch_size=4\n",
    "    IMG_SIZE=512\n",
    "    IMG_SHAPE=(IMG_SIZE,IMG_SIZE,3)\n",
    "    dropout_rate=0.2\n",
    "    num_classes=1\n",
    "    AUTOTUNE=tf.data.experimental.AUTOTUNE\n",
    "    N_SPLITS=5\n",
    "    learning_rate=1e-5\n",
    "    epochs=30\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def seed_all(seed):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONASHSEED']=str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS']='1'\n",
    "\n",
    "seed_all(config.seed)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_data=pd.read_csv('data/Train.csv')\n",
    "test_data=pd.read_csv('data/Test.csv')\n",
    "sub=pd.read_csv('data/SampleSubmission.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "training_data='/media/revanth/01D7A0158DB621C0/competitions/zindi/weekend_hackathon_road_segmentation/'\n",
    "train_data['file_path']=training_data+train_data['Image_ID']+'.jpeg'\n",
    "test_data['file_path']=training_data+test_data['Image_ID']+'.jpeg'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def process_train_data(image_path,label):\n",
    "    image=tf.io.read_file(image_path)\n",
    "    image=tf.io.decode_jpeg(image,channels=3)\n",
    "    p_spatial = tf.random.uniform([], 0, 1.0, dtype = tf.float32)\n",
    "    p_rotate = tf.random.uniform([], 0, 1.0, dtype = tf.float32)\n",
    "    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype = tf.float32)\n",
    "    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype = tf.float32)\n",
    "    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype = tf.float32)\n",
    "    p_crop = tf.random.uniform([], 0, 1.0, dtype = tf.float32)\n",
    "            \n",
    "    # Flips\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    if p_spatial > 0.75:\n",
    "        image = tf.image.transpose(image)\n",
    "        \n",
    "    # Rotates\n",
    "    if p_rotate > 0.75:\n",
    "        image = tf.image.rot90(image, k = 3) # rotate 270ยบ\n",
    "    elif p_rotate > 0.5:\n",
    "        image = tf.image.rot90(image, k = 2) # rotate 180ยบ\n",
    "    elif p_rotate > 0.25:\n",
    "        image = tf.image.rot90(image, k = 1) # rotate 90ยบ\n",
    "        \n",
    "    # Pixel-level transforms\n",
    "    if p_pixel_1 >= 0.4:\n",
    "        image = tf.image.random_saturation(image, lower = 0.7, upper = 1.3)\n",
    "    if p_pixel_2 >= 0.4:\n",
    "        image = tf.image.random_contrast(image, lower = 0.8, upper = 1.2)\n",
    "    if p_pixel_3 >= 0.4:\n",
    "        image = tf.image.random_brightness(image, max_delta = 0.1)\n",
    "        \n",
    "    # Crops\n",
    "    if p_crop > 0.7:\n",
    "        if p_crop > 0.9:\n",
    "            image = tf.image.central_crop(image, central_fraction = 0.7)\n",
    "        elif p_crop > 0.8:\n",
    "            image = tf.image.central_crop(image, central_fraction = 0.8)\n",
    "        else:\n",
    "            image = tf.image.central_crop(image, central_fraction = 0.9)\n",
    "    # elif p_crop > 0.4:\n",
    "    #     crop_size = tf.random.uniform([], int(config.IMG_SIZE * 0.8), config.IMG_SIZE, dtype = tf.int32)\n",
    "    #     image = tf.image.random_crop(image, size = [crop_size, crop_size, 3])\n",
    "\n",
    "    image=tf.image.resize(image,size=[config.IMG_SIZE,config.IMG_SIZE])\n",
    "    image=tf.cast(image,dtype='float32')/255.0\n",
    "    return image, label\n",
    "\n",
    "def process_valid_data(image_path,label):\n",
    "    image=tf.io.read_file(image_path)\n",
    "    image=tf.io.decode_jpeg(image,channels=3)\n",
    "    image=tf.image.resize(image,size=[config.IMG_SIZE,config.IMG_SIZE])\n",
    "    image=tf.cast(image,dtype='float32')/255.0\n",
    "    return image, label\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def getDatasetFromDataframe(train_files, train_labels, val_files, val_labels):\n",
    "\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((train_files, train_labels))\n",
    "    train_ds = train_ds.shuffle(len(train_files))\n",
    "    train_ds = train_ds.map(process_train_data , num_parallel_calls=16)\n",
    "    train_ds = train_ds.batch(config.batch_size)\n",
    "    train_ds = train_ds.prefetch(config.AUTOTUNE)\n",
    "\n",
    "    val_ds = tf.data.Dataset.from_tensor_slices((val_files, val_labels))\n",
    "    val_ds = val_ds.map(process_valid_data , num_parallel_calls=16)\n",
    "    val_ds = val_ds.batch(config.batch_size)\n",
    "    val_ds = val_ds.prefetch(config.AUTOTUNE)\n",
    "    \n",
    "    return train_ds , val_ds"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "skf=StratifiedKFold(n_splits=config.N_SPLITS,shuffle=True,random_state=config.seed)\n",
    "x=train_data['file_path']\n",
    "y=train_data['Target']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_model():\n",
    "    eff=EfficientNetB3(include_top=False,weights='imagenet',input_shape=config.IMG_SHAPE)\n",
    "    eff.trainable=True\n",
    "    out1=GlobalAveragePooling2D()(eff.output)\n",
    "    out2=Dropout(config.dropout_rate)(out1)\n",
    "    out3=Dense(1,activation='sigmoid')(out2)\n",
    "\n",
    "    model=Model(eff.input,out3)\n",
    "    opt=Adam(learning_rate=config.learning_rate)\n",
    "    opt.get_gradients = gctf.centralized_gradients_for_optimizer(opt)\n",
    "    model.compile(\n",
    "        optimizer=opt,\n",
    "        loss=BinaryCrossentropy(),\n",
    "        metrics=AUC())\n",
    "\n",
    "    return model \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for fold ,(train_idx,test_idx) in enumerate(skf.split(x,y)):\n",
    "    print('#'*50)\n",
    "    print(f'FOLD NUMBER : {fold}')\n",
    "    print('#'*50)\n",
    "\n",
    "    x_train,x_test=x.loc[train_idx],x.loc[test_idx]\n",
    "    y_train,y_test=y.loc[train_idx],y.loc[test_idx]\n",
    "    \n",
    "    train_ds,val_ds=getDatasetFromDataframe(x_train.values,y_train.values,x_test.values,y_test.values)\n",
    "  \n",
    "    tf.keras.backend.clear_session()\n",
    "    model=get_model()\n",
    "    weight_path_save = f\"data/models/bestb0_384_model_{str(fold)}_.hdf5\"\n",
    "# last_weight_path = 'last_model.hdf5'\n",
    "\n",
    "    checkpoint = ModelCheckpoint(weight_path_save, \n",
    "                                monitor= 'val_auc', \n",
    "                                verbose=1, \n",
    "                                save_best_only=True, \n",
    "                                mode= 'max', \n",
    "                                save_weights_only = False)\n",
    "\n",
    "\n",
    "    early = EarlyStopping(monitor= 'val_auc', \n",
    "                        mode= 'max', \n",
    "                        patience=5)\n",
    "\n",
    "    reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', patience=2, verbose=1, mode='auto')\n",
    "    callbacks_list = [checkpoint, early, reduceLROnPlat]\n",
    "    model.fit(train_ds,validation_data=val_ds,callbacks=callbacks_list,epochs=config.epochs,verbose=1)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}