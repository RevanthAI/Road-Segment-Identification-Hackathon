{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# import tensorflow-io as tfio\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "import gctf\n",
    "import os\n",
    "import random \n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from tensorflow.keras.applications import EfficientNetB0,EfficientNetB3\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten,GlobalAveragePooling2D,BatchNormalization, Activation\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from tensorflow.keras.losses import BinaryCrossentropy \n",
    "from tensorflow.keras.metrics import AUC"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#class Config is for efficient b3 512 input shape\n",
    "class config:\n",
    "    seed=42\n",
    "    batch_size=4\n",
    "    IMG_SIZE=512\n",
    "    IMG_SHAPE=(IMG_SIZE,IMG_SIZE,3)\n",
    "    dropout_rate=0.2\n",
    "    num_classes=1\n",
    "    AUTOTUNE=tf.data.experimental.AUTOTUNE\n",
    "    N_SPLITS=5\n",
    "    learning_rate=1e-4\n",
    "    epochs=30\n",
    "\n",
    "#class Config1 is for efficient b5 456 input shape\n",
    "\n",
    "class config1:\n",
    "    seed=42\n",
    "    batch_size=4\n",
    "    IMG_SIZE=456\n",
    "    IMG_SHAPE=(IMG_SIZE,IMG_SIZE,3)\n",
    "    dropout_rate=0.4\n",
    "    num_classes=1\n",
    "    AUTOTUNE=tf.data.experimental.AUTOTUNE\n",
    "    N_SPLITS=5\n",
    "    learning_rate=1e-5\n",
    "    epochs=15\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def seed_all(seed):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONASHSEED']=str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS']='1'\n",
    "\n",
    "seed_all(config.seed)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_data=pd.read_csv('data/Test.csv')\n",
    "sub=pd.read_csv('data/SampleSubmission.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "training_data='/media/revanth/01D7A0158DB621C0/competitions/zindi/weekend_hackathon_road_segmentation/'\n",
    "# train_data['file_path']=training_data+train_data['Image_ID']+'.jpeg'\n",
    "test_data['file_path']=training_data+test_data['Image_ID']+'.jpeg'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def process_valid_data(image_path):\n",
    "    image=tf.io.read_file(image_path)\n",
    "    image=tf.io.decode_jpeg(image,channels=3)\n",
    "    image = tf.image.random_brightness(image, 0.3)\n",
    "    image = tf.image.random_flip_left_right(image, seed=None)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image=tf.image.resize(image,size=[config.IMG_SIZE,config.IMG_SIZE])\n",
    "    image=tf.cast(image,dtype='float32')/255.0\n",
    "    return image\n",
    "def process_valid_data1(image_path):\n",
    "    image=tf.io.read_file(image_path)\n",
    "    image=tf.io.decode_jpeg(image,channels=3)\n",
    "    image=tf.image.resize(image,size=[config1.IMG_SIZE,config1.IMG_SIZE])\n",
    "    image=tf.cast(image,dtype='float32')/255.0\n",
    "    return image\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#processing efficientnet b3\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((test_data.file_path.values)).map(process_valid_data , num_parallel_calls=16).batch(config.batch_size).prefetch(config.AUTOTUNE)\n",
    "\n",
    "#Processing efficientnet b5\n",
    "val_ds1 = tf.data.Dataset.from_tensor_slices((test_data.file_path.values)).map(process_valid_data1 , num_parallel_calls=16).batch(config1.batch_size).prefetch(config1.AUTOTUNE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Efficientnet b3 models\n",
    "model_list=['models/best_model_0_.hdf5',\n",
    "'models/best_model_1_.hdf5', \n",
    "'models/best_model_2_.hdf5',\n",
    "'models/best_model_3_.hdf5',\n",
    "'models/best_model_4_.hdf5']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Efficientnet b5 models\n",
    "model_list_2=['models/bestb0_384_model_0_.hdf5',\n",
    "'models/bestb0_384_model_1_.hdf5' ,\n",
    "'models/bestb0_384_model_2_.hdf5']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "preds=[]\n",
    "preds1=[]\n",
    "\n",
    "for i in model_list:\n",
    "    print(i)\n",
    "    model=load_model(i)\n",
    "    preds_test=model.predict(val_ds)\n",
    "    preds.append(preds_test)\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "for i in model_list_2:\n",
    "    print(i)\n",
    "    model=load_model(i)\n",
    "    \n",
    "    preds_test1=model.predict(val_ds1)\n",
    "    preds1.append(preds_test1)\n",
    "    tf.keras.backend.clear_session()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "preds"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sub=pd.read_csv('data/SampleSubmission.csv')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sub.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# sub['Target']=(preds[0]+preds[1]+preds[2]+preds[3]+preds[4])/5\n",
    "sub['Target']=(preds[0]**4+preds[1]**4+preds[2]**4+preds[3]**4+preds[4]**4+preds1[0]**4+preds1[1]**4+preds1[2]**4)/8"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sub.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sub.to_csv('submissions/8_model_average-power-4-ensemble-fold-avg-b5-456-cv-0.0.95',index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('tf_gpu': conda)"
  },
  "interpreter": {
   "hash": "d33e21431fad353c8fdb94506a08045bc3896bf1ad0a6f0b2b9437cafb4d281f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}